[DEFAULT]

job_dir = ./jobs
output_dir = ./jobs/out

batch_size = 128
epochs = 200
test_sample_size = 1024
validation = 8192

type = cvae

dataset = mnist
transformer = simple

optimizer = adam
batch_norm = both

sigma = 0.1

test_latent_sampling = 128
latent_sampling = 1

latent_dim = 256
prior_variance = scalar
prior_means = 0
learned_prior_means = True

features = none
encoder = 512 256
decoder = 256 512
upampler =

output_activation = sigmoid

classifier = 

gamma = 1000

[mnist-dense]

sigma = learned

encoder = 1024 512 512
decoder = 512 512 1024


[mnist-vgg]

transformer = pad

sigma = learned

features = vgg11
encoder = 512 256
decoder = 256 512
upsampler =  512 256 128 64 1

test_batch_size = 128

[imagenet]

dataset = imagenet21k
transformer = crop
data_augmentation = flip crop

epochs = 600

sigma = learned

features = vgg19
encoder = 4096 4096
decoder = 4096 4096
upsampler = 512 256 128 64 3

test_batch_size = 32


[cifar10]

dataset = cifar10
data_augmentation = flip crop

epochs = 600

sigma = learned

features = vgg19
encoder = 
decoder = 
upsampler = 512 256 128 64 3

test_batch_size = 128


[svhn]

data_augmentation = crop

epochs = 500
dataset = svhn

sigma = learned

features = vgg16
encoder = 
decoder = 
upsampler =  512 256 128 64 3

test_batch_size = 128



[fashion]

dataset = fashion
transformer = pad

test_batch_size = 128

epochs = 250
validation = 2048

sigma = learned

features = vgg11
encoder = 512 256

latent_dim = 512
latent_sampling = 1

decoder = 256 512 
upsampler =  512 256 128 64 1


[cifar-ola]
# from olaralex

sigma = 0.05
latent_dim = 1024

features = conv
features_channels = 64 128 512
encoder = 

decoder = 1024

upsampler = 256 64 3


[dai-iclr20]

latent_dim = 512

features = conv
conv_padding = 1
features_channels = 64 128 256

encoder = 

decoder =
# 4096

upsampler = 128 64 3

[dai-iclr20x8]

latent_dim = 512

features = conv
conv_padding = 1
features_channels = 512 1024 256

encoder = 

decoder =
# 4096

upsampler = 1024 512 3


[fashion-vgg16]

dataset = fashion
transformer = pad

features = vgg16

encoder = 512 256

latent_dim = 1024
latent_sampling = 1

decoder = 256 512 
upsampler =  512 256 128 64 1

classifier = 20 10


[mnist-5A]

dataset = fashion
transformer = pad

features = vgg
features_channels = 64 A 128 A 256 256 A 512 512 A 512 512 A

encoder = 512 256

latent_dim = 1024
latent_sampling = 1

decoder = 256 512 
upsampler =  512 256 128 64 1

classifier = 20 10


[autoencoder]

transformer = pad

latent_sampling = 1
latent_dim = 256
sigma = 0
encoder =  512 512
decoder = 512 512
features = conv
conv_padding = 1
features_channels = 16 64
upsampler = 16 3


[vgg-baseline]

type = vib
latent_sampling = 1
latent_dim = 512
sigma = 0
encoder = 
decoder =
classifier = 
features = vgg11
batch_norm = True


[bogus]

coder_means = onehot
latent_sampling = 3
test_batch_size = 1
