[DEFAULT]

job_dir = ./jobs
output_dir = ./jobs/out

batch_size = 128
epochs = 200
test_sample_size = 1024
validation = 8192

type = cvae

dataset = mnist
transformer = simple

optimizer = adam
batch_norm = both

sigma = 0.1

test_latent_sampling = 128
latent_sampling = 1

latent_dim = 256
coder_means = random
dictionary_variance = 1

features = none
encoder = 512 256
decoder = 256 512
upampler =

output_activation = sigmoid

classifier = 

gamma = 1000

[mnist-dense]

sigma = coded

encoder = 1024 512 512
decoder = 512 512 1024
coder_means = learned
dictionary_variance = 0


[mnist-vgg]

transformer = pad

sigma = coded

features = vgg11
encoder = 512 256
decoder = 256 512
upsampler =  512 256 128 64 1
coder_means = learned
dictionary_variance = 0

test_batch_size = 128


[cifar10]

dataset = cifar10
data_augmentation = flip crop

epochs = 600

sigma = coded

features = vgg19
encoder = 
decoder = 
upsampler = 512 256 128 64 3
coder_means = learned
dictionary_variance = 0

test_batch_size = 128


[svhn]

data_augmentation = crop

epochs = 500
dataset = svhn

sigma = coded

features = vgg16
encoder = 
decoder = 
upsampler =  512 256 128 64 3
coder_means = learned
dictionary_variance = 0

test_batch_size = 128


[cifar-ola]
# from olaralex

sigma = 0.05
latent_dim = 1024

features = conv
features_channels = 64 128 512
encoder = 

decoder = 1024

upsampler = 256 64 3

[dai-iclr20]

latent_dim = 512

features = conv
conv_padding = 1
features_channels = 64 128 256

encoder = 

decoder =
# 4096

upsampler = 128 64 3

[dai-iclr20x8]

latent_dim = 512

features = conv
conv_padding = 1
features_channels = 512 1024 256

encoder = 

decoder =
# 4096

upsampler = 1024 512 3

[dense]

dataset = mnist
features = none
upsampler = 
latent_dim = 128
latent_sampling = 1
encoder = 1024 512 512
decoder = 512 512 1024


[fashion-vgg11]

dataset = fashion
transformer = pad

features = vgg11

encoder = 512 256

latent_dim = 1024
latent_sampling = 1

decoder = 256 512 
upsampler =  512 256 128 64 1

classifier = 20 10

[fashion-vgg16]

dataset = fashion
transformer = pad

features = vgg16

encoder = 512 256

latent_dim = 1024
latent_sampling = 1

decoder = 256 512 
upsampler =  512 256 128 64 1

classifier = 20 10


[mnist-5A]

dataset = fashion
transformer = pad

features = vgg
features_channels = 64 A 128 A 256 256 A 512 512 A 512 512 A

encoder = 512 256

latent_dim = 1024
latent_sampling = 1

decoder = 256 512 
upsampler =  512 256 128 64 1

classifier = 20 10


[cifar10-vgg11]

features = vgg11

encoder = 512 256

latent_dim = 1024
latent_sampling = 1

decoder = 256 512 

upsampler = 512 256 128 64 3

classifier = 20 10


[cifar10-vgg16]

features = vgg16

encoder = 1024 512 512

latent_dim = 256
latent_sampling = 1

decoder = 512 512 1024

upsampler = 512 256 128 64 3

classifier = 20 10



[autoencoder]

latent_sampling = 1
latent_dim = 256
sigma = 0
encoder =  512 512
decoder = 512 512
features_channels = 16 64
upsampler = 16 3


[vgg-baseline]

type = vib
latent_sampling = 1
latent_dim = 512
sigma = 0
encoder = 
decoder =
classifier = 
features = vgg11
batch_norm = True

[bogus]

coder_means = onehot
latent_sampling = 3
test_batch_size = 1